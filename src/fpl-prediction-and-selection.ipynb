{
 "cells": [
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pulp\n",
    "\n",
    "import unidecode"
   ],
   "execution_count": 185,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "## Read data\n",
    "\n",
    "# Players df contains the summary of player performance from each season\n",
    "# Each row represents one player\n",
    "\n",
    "## GWs df contains the information of each player for each gameweek\n",
    "## Each row represents a player's performance for a gameweek\n",
    "\n",
    "folderpath = r'../data/input/fantasypremierleague/'\n",
    "players_1617_df = pd.read_csv(folderpath +'players_raw_1617.csv')\n",
    "players_1718_df = pd.read_csv(folderpath+'players_raw_1718.csv')\n",
    "players_1819_df = pd.read_csv(folderpath+'players_raw_1819.csv')\n",
    "players_1920_df = pd.read_csv(folderpath+'players_raw_1920.csv')\n",
    "players_2021_df = pd.read_csv(folderpath+'players_raw_2021.csv')\n",
    "players_2122_df = pd.read_csv(folderpath+'players_raw_2122.csv')\n",
    "players_2223_df = pd.read_csv(folderpath+'players_raw_2223.csv')\n",
    "players_2324_df = pd.read_csv(folderpath+'players_raw_2324.csv')\n",
    "\n",
    "gws_1617_df = pd.read_csv(folderpath+'merged_gw_1617.csv', encoding='latin')\n",
    "gws_1718_df = pd.read_csv(folderpath+'merged_gw_1718.csv',encoding='latin')\n",
    "gws_1819_df = pd.read_csv(folderpath+'merged_gw_1819.csv',encoding='latin')\n",
    "gws_1920_df = pd.read_csv(folderpath+'merged_gw_1920.csv',engine='python')\n",
    "gws_2021_df = pd.read_csv(folderpath+'merged_gw_2021.csv',encoding='latin')\n",
    "gws_2122_df = pd.read_csv(folderpath+'merged_gw_2122.csv',encoding='latin')\n",
    "gws_2223_df = pd.read_csv(folderpath+'merged_gw_2223.csv',encoding='latin')\n",
    "gws_2324_df = pd.read_csv(folderpath+'merged_gw_2324.csv',engine='python')\n",
    "\n",
    "team_codes_df = pd.read_csv('../data/teams.csv')\n"
   ],
   "execution_count": 186,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Clean the headers to be used later\n",
    "team_codes_df.columns.values[2:] = team_codes_df.columns[2:].str.replace('team_', '')"
   ],
   "execution_count": 187,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Clean and process dataframes\n",
    "\n",
    "\n",
    "For both types of dataframes, I want to add:\n",
    "- Player position\n",
    "- Full name (since the names are inconsistent across seasons and between dataframes)\n",
    "\n",
    "\n",
    "\n",
    "Also, it turns out that there are 2 Danny Wards in the 18/19 season. I am still thinking of a good way to represent both. But, since the are both fringe players in that season (total of 0 points between them), I will remove them for now (sorry!)\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# remove Danny Wards from 18/19 season\n",
    "players_1819_df = players_1819_df[((players_1819_df.first_name == \"Danny\") & (players_1819_df.second_name==\"Ward\"))==False]\n",
    "gws_1819_df = gws_1819_df[gws_1819_df.name.str.contains(\"Danny_Ward\")==False]"
   ],
   "execution_count": 188,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "player_df_list = [players_1617_df, players_1718_df, players_1819_df, players_1920_df, players_2021_df, players_2122_df, players_2223_df]\n",
    "gw_df_list = [gws_1617_df, gws_1718_df, gws_1819_df, gws_1920_df, gws_2021_df, gws_2122_df, gws_2223_df]"
   ],
   "execution_count": 189,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# append season and season index to dfs\n",
    "\n",
    "seasons = ['1617', '1718', '1819', '1920', '2021', '2122', '2223']\n",
    "season_nums = list(range(len(seasons)))\n",
    "\n",
    "for i in range(len(seasons)):\n",
    "    \n",
    "    player_df_list[i]['season'] = seasons[i]\n",
    "    gw_df_list[i]['season'] = seasons[i]\n",
    "    \n",
    "    player_df_list[i]['season_num'] = season_nums[i]\n",
    "    gw_df_list[i]['season_num'] = season_nums[i]"
   ],
   "execution_count": 190,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# combine dataframes from all seasons into one\n",
    "\n",
    "players_df = pd.concat(player_df_list)\n",
    "gws_df = pd.concat(gw_df_list)\n",
    "\n",
    "players_df.reset_index(inplace=True)\n",
    "gws_df.reset_index(inplace=True)"
   ],
   "execution_count": 191,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "## Get full name\n",
    "# Cleans up accents and also makes processing easier\n",
    "\n",
    "def get_full_name_playerdf(first_name, second_name):\n",
    "    full_name = first_name +'_' + second_name\n",
    "    full_name = full_name.replace(\" \", \"_\")\n",
    "    full_name = full_name.replace(\"-\", \"_\")\n",
    "    full_name = unidecode.unidecode(full_name)\n",
    "    \n",
    "    return full_name\n",
    "\n"
   ],
   "execution_count": 192,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Translate player positions into string for easier readability\n",
    "\n",
    "positions_dict = {\n",
    "    1: 'Keeper',\n",
    "    2: 'Defender',\n",
    "    3: 'Midfielder',\n",
    "    4: 'Forward'\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "players_df['full_name'] = players_df.apply(lambda x: get_full_name_playerdf(x.first_name, x.second_name), axis=1).str.lower()\n",
    "players_df['position'] = players_df.element_type.map(positions_dict)\n",
    "players_df['starting_cost'] = players_df.now_cost - players_df.cost_change_start_fall\n",
    "players_df['cost_bin'] = players_df.now_cost.apply(lambda x: np.floor(x/10))\n",
    "\n",
    "\n",
    "\n",
    "gws_df['full_name'] = gws_df.name.str.replace('_\\d+','')\n",
    "gws_df['full_name'] = gws_df['full_name'].str.replace(\" \", \"_\").str.replace(\"-\", \"_\").str.replace('_\\d+','')\n",
    "gws_df['full_name'] = gws_df['full_name'].apply(lambda x: unidecode.unidecode(x))\n",
    "gws_df['full_name'] = gws_df['full_name'].str.lower()\n"
   ],
   "execution_count": 193,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "    \n",
    "def clean_gw_df(player_df, gw_df, team_codes_df):\n",
    "    \n",
    "    # Returns a df with player position, player's team name, and opponent's team name\n",
    "    \n",
    "    pdf = player_df.copy()[['full_name', 'season', 'position', 'player_team_name']]\n",
    "    gdf = gw_df.copy()\n",
    "    \n",
    "    gdf = gdf.merge(pdf, on=['full_name', 'season'], how='left')\n",
    "    \n",
    "    \n",
    "    dfs = []\n",
    "    for s, group in gdf.groupby('season'):\n",
    "\n",
    "        temp_code_df = team_codes_df[['team', s]]\n",
    "        temp_code_df = temp_code_df.dropna()\n",
    "        \n",
    "        group = group[['opponent_team']]\n",
    "        group['opponent_team_name'] = group.opponent_team.map(temp_code_df.set_index(s).team)\n",
    "        dfs.append(group[['opponent_team_name']])\n",
    "        \n",
    "    out_df = pd.concat(dfs, axis=0)\n",
    "    out_df = pd.concat([gdf, out_df], axis=1)\n",
    "\n",
    "    return out_df"
   ],
   "execution_count": 194,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "gws_df.opponent_team = gws_df.opponent_team.astype(float)\n",
    "players_df['player_team_name'] = players_df.team_code.map(team_codes_df.set_index('team_code').team)\n",
    "gws_df = clean_gw_df(players_df, gws_df, team_codes_df)"
   ],
   "execution_count": 195,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Approach\n",
    "\n",
    "To get the initial team, I will rely on a simple method of picking the players with the most points based on last season.\n",
    "\n",
    "A brief recap on the current the FPL rules:\n",
    "\n",
    "1. A team must have 15 players\n",
    "2. A team must have:\n",
    "   - 2 Goalkeepers\n",
    "   - 5 Defenders\n",
    "   - 5 Midfielders\n",
    "   - 3 Forwards\n",
    "3. The total value of the initial squad must not exceed 100 million\n",
    "4. There can only be a maximum of 3 players from a single team\n",
    "5. Only the starting 11 will gain points for the FPL team\n",
    "6. A captain's score is doubled. \n",
    "7. Each gameweek, one free transfer is allowed. Each additional transfer will cost 4 points (not money!) \n",
    "\n",
    "Due to the complexity of the FPL mechanism, I have chosen to focus only on the above rules for now. There are also other rules that I plan on incorporating into my model:\n",
    "\n",
    "8. If a player in the starting 11 is unavailable (due to injury or suspension etc.), they will be substituted by the first player on the bench.\n",
    "9. If the captain is unavailable, the vice-captain's score is doubled instead.\n",
    "10. If the free transfer each week is not used, it can be carried over to the next Gameweek (for a maximum of 2 free transfers for a given Gameweek).\n",
    "11. There are a number of wildcards that can boost the points obtained in a Gameweek\n",
    "\n",
    "\n",
    "I will first use a linear programming approach to optimize the initial team. Then, I will build a regression model to forecast the predicted points for each player for each Gameweek, and use a heuristic-based algorithm to determine the best transfer (if any) to make for each Gameweek.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Picking the initial team of 15 players\n",
    "\n",
    "I decided to go with the simple approach of using the performance of players in the previous season (18/19) as the basis of selection into the team. Using linear programming, I will optimize for the maximum number of points scored in the 18/19 season, with the following constraints:\n",
    "\n",
    "- Total budget of 1000 \n",
    "- 1 keeper\n",
    "- 4 defenders\n",
    "- 4 midfielders\n",
    "- 2 forwards\n",
    "- not more than 3 players from the same team\n",
    "\n",
    "Since benched players do not contribute to Gameweek points, I will first pick the 4 cheapest players (1 from each position) in order to maximize the amount of money I can use for the starting 11. To do this, I simply\n",
    "\n",
    "Since I am using the 19/20 season as the test set, I will use the 18/19 season to pick my initial team."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, let's get the players who are available in the current season. This is necessary because some players would have been relegated/promoted after the previous season, and also because players would have been transferred between clubs (of different leagues)."
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def make_available_players_df(this_season_player_df, last_season_player_df):\n",
    "    \n",
    "    \n",
    "    last_season_player_df = last_season_player_df[last_season_player_df.minutes > 0]\n",
    "    last_season_player_df = last_season_player_df[['full_name', \"total_points\"]]\n",
    "    last_season_player_df.rename(columns={'total_points': \"total_points_last_season\"},\n",
    "                                inplace=True)\n",
    "    \n",
    "    available_players_df = pd.merge(this_season_player_df,\n",
    "                                    last_season_player_df,\n",
    "                                   on='full_name', how='left')\n",
    "    \n",
    "    available_players_df.total_points_last_season = available_players_df.groupby(['position', 'cost_bin']).total_points_last_season.transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    return available_players_df"
   ],
   "execution_count": 196,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "current_season_player_df = players_df[players_df.season=='2223']\n",
    "previous_season_player_df = players_df[players_df.season=='2122']\n",
    "\n",
    "available_players_df = make_available_players_df(current_season_player_df, previous_season_player_df)"
   ],
   "execution_count": 197,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def get_cheapest_players(player_df):\n",
    "    \n",
    "    cheapest_player_names = []\n",
    "    total_cost = 0\n",
    "    \n",
    "    # for each position, sort the players by cost (in ascending order)\n",
    "    # then, get the player with the most number of points\n",
    "    \n",
    "    for position, group in player_df.groupby('position'):\n",
    "        cheapest_players =  group[(group.starting_cost == group.starting_cost.min())]\n",
    "        top_cheapest_player = cheapest_players[cheapest_players.total_points == cheapest_players.total_points.max()]\n",
    "        \n",
    "        cheapest_player_name = top_cheapest_player.full_name.values[0]\n",
    "        \n",
    "        cheapest_player_names += [cheapest_player_name]\n",
    "        total_cost += top_cheapest_player.starting_cost.values[0]\n",
    "        \n",
    "        print(position, \": \", cheapest_player_name )\n",
    "        \n",
    "    return cheapest_player_names, total_cost"
   ],
   "execution_count": 198,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "bench_players, bench_cost = get_cheapest_players(available_players_df)"
   ],
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defender :  daniel_amartey\n",
      "Forward :  sam_greenwood\n",
      "Keeper :  stefan_ortega_moreno\n",
      "Midfielder :  leon_bailey\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Optimizing for starting 11\n",
    "\n",
    "Now that I have my bench players, I'll go ahead and optimize for the starting 11. Again, here I am using the actual results of the previous season. The reasoning here is that, at least for the first Gameweek, the players who are most likely to perform well are the players who have performed well in the last season (in the absence of other information). Of course, one can also try to predict the total number of points a player will score in the current season, but in the absence of any information about the current season, I am doubtful that the prediction will be meaningful or fare better than this simple heuristic. This is something that I am planning to look into soon!\n",
    "\n",
    "First, a bunch of helper functions to make life easier:"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def make_decision_variables(player_df):\n",
    "    return [pulp.LpVariable(i, cat=\"Binary\") for i in player_df.full_name]"
   ],
   "execution_count": 200,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def make_optimization_function(player_df, decision_variables):\n",
    "    op_func = \"\"\n",
    "\n",
    "    for i, player in enumerate(decision_variables):\n",
    "        op_func += player_df.total_points_last_season[i]*player\n",
    "        \n",
    "    return op_func"
   ],
   "execution_count": 201,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def make_cash_constraint(player_df, decision_variables, available_cash):\n",
    "    total_paid = \"\"\n",
    "    for rownum, row in player_df.iterrows():\n",
    "        for i, player in enumerate(decision_variables):\n",
    "            if rownum == i:\n",
    "                formula = row['starting_cost']*player\n",
    "                total_paid += formula\n",
    "\n",
    "    return (total_paid <= available_cash)"
   ],
   "execution_count": 202,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def make_player_constraint(position, n, decision_variables, player_df):\n",
    "    \n",
    "    total_n = \"\"\n",
    "    \n",
    "    player_positions = player_df.position\n",
    "    \n",
    "    for i, player in enumerate(decision_variables):\n",
    "        if player_positions[i] == position:\n",
    "            total_n += 1*player\n",
    "            \n",
    "    return(total_n == n)"
   ],
   "execution_count": 203,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def add_team_constraint(prob, player_df, decision_variables):\n",
    "\n",
    "    for team, group in player_df.groupby('team_code'):\n",
    "        team_total = ''\n",
    "        \n",
    "        for player in decision_variables:\n",
    "            if player.name in group.full_name.values:\n",
    "                formula = 1*player\n",
    "                team_total += formula\n",
    "                \n",
    "        \n",
    "        prob += (team_total <= 3)"
   ],
   "execution_count": 204,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "available_cash = 1000 - bench_cost\n",
    "\n",
    "prob = pulp.LpProblem('InitialTeam', pulp.LpMaximize)\n",
    "\n",
    "decision_variables = make_decision_variables(available_players_df)\n",
    "prob += make_optimization_function(available_players_df, decision_variables)\n",
    "prob += make_cash_constraint(available_players_df, decision_variables, available_cash)\n",
    "prob += make_player_constraint(\"Keeper\", 1, decision_variables, available_players_df) \n",
    "prob += make_player_constraint(\"Defender\", 4, decision_variables, available_players_df) \n",
    "prob += make_player_constraint(\"Midfielder\", 4, decision_variables, available_players_df) \n",
    "prob += make_player_constraint(\"Forward\", 2, decision_variables, available_players_df)\n",
    "\n",
    "add_team_constraint(prob, available_players_df, decision_variables)"
   ],
   "execution_count": 205,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "from pulp import LpSolverDefault\n",
    "\n",
    "## Solve\n",
    "LpSolverDefault.msg = 1\n",
    "prob.writeLP('InitialTeam.lp')\n",
    "optimization_result = prob.solve()\n"
   ],
   "execution_count": 206,
   "outputs": [
    {
     "ename": "PulpError",
     "evalue": "Repeated variable names:\n[('ben_davies', 2)]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPulpError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[206], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m## Solve\u001B[39;00m\n\u001B[0;32m      4\u001B[0m LpSolverDefault\u001B[38;5;241m.\u001B[39mmsg \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mprob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwriteLP\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mInitialTeam.lp\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m optimization_result \u001B[38;5;241m=\u001B[39m prob\u001B[38;5;241m.\u001B[39msolve()\n",
      "File \u001B[1;32mD:\\Moi\\Travail\\ESME\\INGE3\\SEMESTRE 9\\UE5 Projet\\projet\\Lib\\site-packages\\pulp\\pulp.py:1796\u001B[0m, in \u001B[0;36mLpProblem.writeLP\u001B[1;34m(self, filename, writeSOS, mip, max_length)\u001B[0m\n\u001B[0;32m   1784\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwriteLP\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename, writeSOS\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, mip\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m):\n\u001B[0;32m   1785\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1786\u001B[0m \u001B[38;5;124;03m    Write the given Lp problem to a .lp file.\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1794\u001B[0m \u001B[38;5;124;03m        - The file is created\u001B[39;00m\n\u001B[0;32m   1795\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1796\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmpslp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwriteLP\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1797\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriteSOS\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriteSOS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmip\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\n\u001B[0;32m   1798\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Moi\\Travail\\ESME\\INGE3\\SEMESTRE 9\\UE5 Projet\\projet\\Lib\\site-packages\\pulp\\mps_lp.py:351\u001B[0m, in \u001B[0;36mwriteLP\u001B[1;34m(LpProblem, filename, writeSOS, mip, max_length)\u001B[0m\n\u001B[0;32m    349\u001B[0m vs \u001B[38;5;241m=\u001B[39m LpProblem\u001B[38;5;241m.\u001B[39mvariables()\n\u001B[0;32m    350\u001B[0m \u001B[38;5;66;03m# check for repeated names\u001B[39;00m\n\u001B[1;32m--> 351\u001B[0m \u001B[43mLpProblem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheckDuplicateVars\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;66;03m# Bounds on non-\"positive\" variables\u001B[39;00m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;66;03m# Note: XPRESS and CPLEX do not interpret integer variables without\u001B[39;00m\n\u001B[0;32m    354\u001B[0m \u001B[38;5;66;03m# explicit bounds\u001B[39;00m\n\u001B[0;32m    355\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mip:\n",
      "File \u001B[1;32mD:\\Moi\\Travail\\ESME\\INGE3\\SEMESTRE 9\\UE5 Projet\\projet\\Lib\\site-packages\\pulp\\pulp.py:1815\u001B[0m, in \u001B[0;36mLpProblem.checkDuplicateVars\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1811\u001B[0m repeated_names \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   1812\u001B[0m     (key, value) \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(repeated_names\u001B[38;5;241m.\u001B[39mitems()) \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m   1813\u001B[0m ]\n\u001B[0;32m   1814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repeated_names:\n\u001B[1;32m-> 1815\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m const\u001B[38;5;241m.\u001B[39mPulpError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepeated variable names:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(repeated_names))\n\u001B[0;32m   1816\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mPulpError\u001B[0m: Repeated variable names:\n[('ben_davies', 2)]"
     ]
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "## Get initial team\n",
    "\n",
    "def get_initial_team(prob, player_df):\n",
    "    \n",
    "    variable_names = [v.name for v in prob.variables()]\n",
    "    variable_values = [v.varValue for v in prob.variables()]\n",
    "\n",
    "    initial_team = pd.merge(pd.DataFrame({'full_name': variable_names,\n",
    "                  'selected': variable_values}),\n",
    "                                       player_df, on=\"full_name\")\n",
    "    \n",
    "    initial_team = initial_team[initial_team.selected==1.0] \n",
    "    \n",
    "    return initial_team\n",
    "\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "initial_team_df = get_initial_team(prob, available_players_df)\n",
    "initial_team_df[['full_name', \"position\", \"starting_cost\", \"player_team_name\"]]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "## Sanity check\n",
    "\n",
    "def sanity_check(team_df):\n",
    "    print('Sanity check for starting 11: ')\n",
    "    print('*'*88) \n",
    "    \n",
    "    print('Number of players in each position: ')\n",
    "    for pos, group in team_df.groupby('position'):\n",
    "        print(pos, ': ', len(group), sep='')\n",
    "        \n",
    "    \n",
    "    print('*'*88)   \n",
    "    print('Number of players from each team: ')\n",
    "    print(team_df.groupby('player_team_name').position.count())\n",
    "    \n",
    "    print('*'*88)    \n",
    "    print('Total cost:', team_df.starting_cost.sum())\n",
    "    \n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "sanity_check(initial_team_df)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Performance of initial team\n",
    "\n",
    "Right off the bat, how does this team fare in the 19/20 season?\n",
    "\n",
    "Note: I selected the highest scoring player in the 18/19 season as the captain for the 19/20 season"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "captain = get_initial_team(prob, previous_season_player_df).sort_values(\"total_points\", ascending=False).head(1).full_name.values[0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "captain = get_initial_team(prob, previous_season_player_df).sort_values(\"total_points\", ascending=False).head(1).full_name.values[0]\n",
    "\n",
    "total_points = current_season_player_df[current_season_player_df.full_name.isin(initial_team_df.full_name)].total_points.sum()\n",
    "total_points += current_season_player_df[current_season_player_df.full_name==captain].total_points\n",
    "\n",
    "print(\"Total points for 23/24 season:\", total_points.values[0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How does this compare to the rest of the FPL managers? Unfortunately there is no data available on historic FPL manager ranking, but with some Googling I managed to find someone with the exact same score of 1792 in the 19/20 season (https://fantasy.premierleague.com/entry/299659/history)\n",
    "\n",
    "This manager ranked 4375672. According to https://www.premierleague.com/news/1252542, there were 7.6 million managers last season. This translates to a final standing of the top 57.57% of managers. Not bad, but not great either.\n",
    "\n",
    "This initial score was calculated based on a strategy of \"set it and forget it\" - once the initial team was selected, the captain was selected as well, and I just left it to run for the whole season. No wildcards were played, no transfers were made, and no substitutions were made (so, in some weeks, a player could have had 0 points because they were not playing - but, I have yet to check if this is true for this team).\n",
    "\n",
    "Next, I will take a look at how we can improve this score by making weekly transfers!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modeling\n",
    "\n",
    "## Approach:\n",
    "\n",
    "- Use each player's performance in previous Gameweeks to predict total points for this Gameweek.\n",
    "- Use team and opponent performance in previous Gameweeks as well\n",
    "\n",
    "This will be done by creating lagged versions of selected features such as cumulative goals scored/conceded by the player's team as well as their opponent. Each player's contribution will also be taken into account by creating the corresponding lagged features at the player level, as well by incorporating what FPL clas the \"ICT\" variables - intensity, creativty, and threat - which related to a player's performance on the pitch that did not directly relate to goals (but relate to creating goal-scoring opportunities and build-up play)\n",
    "\n",
    "\n",
    "- Use previous Gameweek's performance to predict total points for next gameweek\n",
    "- Calculate a rolling average\n",
    "- Also use previous season's total points as a predictor, as the predictions for the earlier gameweeks might be extremely noisy. This is important as we don't want star players to be transfered out just because they had a bad start\n",
    "- For players without data from past seasons, replace with average of players in the same position and similar cost (rounded to nearest 10m)\n",
    "\n",
    "- Only include players who had played (i.e. minutes > 0) to reduce noise"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Again, some helper functions to make life easier:"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def get_team_points(was_home, h_score, a_score):\n",
    "    \n",
    "    if h_score == a_score:\n",
    "        return 1\n",
    "    \n",
    "    if h_score > a_score:\n",
    "        if was_home:\n",
    "            return 3\n",
    "        else: \n",
    "            return 0\n",
    "    \n",
    "    if h_score < a_score:\n",
    "        if was_home:\n",
    "            return 0\n",
    "        else: \n",
    "            return 3"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def get_opponent_points(team_points):\n",
    "    if team_points == 1:\n",
    "        return 1\n",
    "    \n",
    "    if team_points == 3:\n",
    "        return 0\n",
    "    \n",
    "    if team_points == 0:\n",
    "        return 3"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "gws_df['team_points']= gws_df.apply(lambda x: get_team_points(x.was_home, x.team_h_score, x.team_a_score), axis=1)\n",
    "gws_df['opponent_points'] = gws_df.team_points.apply(lambda x: get_opponent_points(x))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def player_lag_features(gw_df, features, lags):\n",
    "    \n",
    "    out_df = gw_df.copy()\n",
    "    lagged_features = []\n",
    "    \n",
    "    for feature in features:\n",
    "            \n",
    "        for lag in lags:\n",
    "            \n",
    "            lagged_feature = 'last_' + str(lag) + '_' + feature\n",
    "            \n",
    "            if lag == 'all':\n",
    "                out_df[lagged_feature] = out_df.sort_values('round').groupby(['season', 'full_name'])[feature]\\\n",
    "            .apply(lambda x: x.cumsum() - x)\n",
    "                \n",
    "            else:\n",
    "\n",
    "                out_df[lagged_feature] = out_df.sort_values('round').groupby(['season', 'full_name'])[feature]\\\n",
    "                .apply(lambda x: x.rolling(min_periods=1, window=lag+1).sum() - x)\n",
    "\n",
    "            lagged_features.append(lagged_feature)\n",
    "    \n",
    "    return out_df, lagged_features"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def team_lag_features(gw_df, features, lags):\n",
    "    out_df = gw_df.copy()\n",
    "    lagged_features = []\n",
    "    \n",
    "    for feature in features:\n",
    "\n",
    "        ## Create a df for each feature\n",
    "        ## Then, self-join so that the opponent info for that feature is included\n",
    "        ## Then, create lagged features and join the columns to the feature df\n",
    "        ## Do the same for the opponent feature\n",
    "        ## Exit loop, merge with the original df\n",
    "        \n",
    "        feature_name = feature + '_team'\n",
    "        opponent_feature_name = feature_name + '_opponent'\n",
    "        \n",
    "  \n",
    "        feature_team = out_df.groupby(['player_team_name', 'season', 'round', 'kickoff_time', 'opponent_team_name'])\\\n",
    "                        [feature].max().rename(feature_name).reset_index()\n",
    "        \n",
    "        # self join to get opponent info\n",
    "        \n",
    "        feature_team = feature_team.merge(feature_team,\n",
    "                          left_on=['player_team_name', 'season', 'round', 'kickoff_time', 'opponent_team_name'],\n",
    "                          right_on=['opponent_team_name', 'season', 'round', 'kickoff_time', 'player_team_name'],\n",
    "                          how='left',\n",
    "                          suffixes=('', '_opponent'))\n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "        for lag in lags:\n",
    "            lagged_feature_name = 'last_' + str(lag) + '_' + feature_name\n",
    "            lagged_opponent_feature_name = 'opponent_last_' + str(lag) + '_' + feature\n",
    "            \n",
    "\n",
    "            if lag == 'all':\n",
    "                \n",
    "                feature_team[lagged_feature_name] = feature_team.sort_values('round').groupby('player_team_name')[feature_name]\\\n",
    "                                                .apply(lambda x: x.cumsum() - x)\n",
    "            \n",
    "                feature_team[lagged_opponent_feature_name] = feature_team.groupby('player_team_name')[opponent_feature_name]\\\n",
    "                                                .apply(lambda x: x.cumsum() - x)\n",
    "            else:\n",
    "                    \n",
    "                       \n",
    "                feature_team[lagged_feature_name] = feature_team.sort_values('round').groupby('player_team_name')[feature_name]\\\n",
    "                                                    .apply(lambda x: x.rolling(min_periods=1,\n",
    "                                                                              window=lag+1).sum()-x)\n",
    "\n",
    "                feature_team[lagged_opponent_feature_name] = feature_team.groupby('player_team_name')[opponent_feature_name]\\\n",
    "                                                    .apply(lambda x: x.rolling(min_periods=1,\n",
    "                                                                              window=lag+1).sum()-x)\n",
    "\n",
    "            lagged_features.extend([lagged_feature_name, lagged_opponent_feature_name])\n",
    "            \n",
    "        out_df = out_df.merge(feature_team,\n",
    "                             on=['player_team_name', 'season', 'round', 'kickoff_time', 'opponent_team_name'],\n",
    "                             how='left')\n",
    "        \n",
    "        \n",
    "        return out_df, lagged_features"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "player_features_to_lag = [\n",
    "    'assists',\n",
    "     'bonus',\n",
    "     'bps',\n",
    "     'creativity',\n",
    "     'clean_sheets',\n",
    "     'goals_conceded',\n",
    "     'goals_scored',\n",
    "     'ict_index',\n",
    "     'influence',\n",
    "     'minutes',\n",
    "     'threat']\n",
    "\n",
    "team_features_to_lag = ['goals_conceded', 'goals_scored', 'team_points', 'opponent_points']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "lagged_gw_df_players, lagged_player_features = player_lag_features(gws_df, player_features_to_lag, ['all', 1, 3, 5])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "lagged_gw_df, lagged_team_features = team_lag_features(lagged_gw_df_players, team_features_to_lag, ['all', 1, 3, 5])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "relevant_features = ['position', 'was_home', 'minutes', 'value', 'round', 'season_num'] + \\\n",
    "    lagged_player_features + \\\n",
    "    lagged_team_features "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modelling\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def make_dummies(df, numerical_features, categorical_features):\n",
    "    \n",
    "  \n",
    "    X_num = df[numerical_features]\n",
    "    X_cat = df[categorical_features]\n",
    "    \n",
    "    X_cat = X_cat.astype(str)\n",
    "    X_cat = pd.get_dummies(X_cat)\n",
    "    \n",
    "    # Join categorical and numerical features\n",
    "    X = pd.concat([X_num, X_cat], axis=1)\n",
    "    \n",
    "    return X"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "categorical_features = ['was_home', 'position']\n",
    "numerical_features = numerical_features = list(set(relevant_features) - set(categorical_features))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "train_df = lagged_gw_df[(lagged_gw_df.season!='1920')]\n",
    "test_df = lagged_gw_df[(lagged_gw_df.season=='1920') ]\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# XGBoost handles NA values, but the other scikit learn methods (that I've chosen) do not\n",
    "\n",
    "lagged_gw_df_no_na = lagged_gw_df.dropna(subset=relevant_features + ['total_points', 'season'])\n",
    "train_df_no_na = lagged_gw_df_no_na[lagged_gw_df_no_na.season!='1920']\n",
    "test_df_no_na = lagged_gw_df_no_na[lagged_gw_df_no_na.season=='1920']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "X_train = make_dummies(train_df[relevant_features], numerical_features, categorical_features)\n",
    "y_train = train_df.total_points\n",
    "\n",
    "X_train_no_na = make_dummies(train_df_no_na[relevant_features], numerical_features, categorical_features)\n",
    "y_train_no_na = train_df_no_na.total_points"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "X_test = make_dummies(test_df, numerical_features, categorical_features)\n",
    "y_test = test_df.total_points\n",
    "\n",
    "X_test_no_na = make_dummies(test_df_no_na, numerical_features, categorical_features)\n",
    "y_test_no_na = test_df_no_na.total_points"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Regression models\n",
    "\n",
    "For a start, I have chosen to look at:\n",
    "\n",
    "- Linear regression and its variants, Lasso and Ridge\n",
    "- XGBoost\n",
    "- A simple baseline model of using group means\n",
    "\n",
    "For the XGBoost regressor, I will first do a randomized search to tune the hyperparameters. One risk of this approach is that time and resources will be wasted on tuning the hyperparameters if it turns out that a much simpler model that doesn't require hyperparameter tuning (e.g. linear regression) performs much better than XGBoost. But, given that XGBoost has known to almost always outperform most other models, it is at least worth a shot.\n",
    "\n",
    "Then, all models will be compared and the top 2 (with the highest cross-validation score - here I use RMSE) will be used to make predictions to be fed into the algorithm to select potential transfers for each gameweek.\n",
    "\n",
    "A brief explanation on the starting values I have selected for the tuning of the hyperparameters:\n",
    "\n",
    "`max_depth`: larger values makes the model (1) more complex, (2) more likely to overfit, and (3) take longer to train. Here, I used a range from 3-6 (the default). I am wary of overfitting since the nature of the data can change dramatically across seasons (e.g. due to player transfers, improvement/decline of play abilities, state of the club etc.). \n",
    "\n",
    "`min_child_weight`: Similar to `max_depth`, I want to reduce the complexity/variance in the model. Here, larger values will reduce the likelihood of overfitting. I decided to use a range from 6-10\n",
    "\n",
    "`learning_rate`: The default here is 0.3. I decided to try 5 values: 1/10 of the default, 1/5 of the default, 1.5x the default, and 2x the default.\n",
    "\n",
    "`subsample` and `colsample_by_tree`: The default here is 1, but since I want to reduce overfitting, I decided to use a range from 0.8 - 0.9. \n",
    "\n"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "params = {\n",
    "         'max_depth': list(range(3,7)),  \n",
    "    'min_child_weight': list(range(10,51)),\n",
    "    'learning_rate':  [0.03, 0.15, 0.3, 0.45, 0.6],\n",
    "    'subsample': stats.uniform(0.8, 0.1),\n",
    "    'colsample_bytree': [0.8, 0.1]}\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "xgb_cv = RandomizedSearchCV(xgb_reg, params, cv=3, scoring='neg_root_mean_squared_error',\n",
    "                            random_state=999)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "xgb_cv.fit(X_train, y_train)\n",
    "xgb_best = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "xgb_best.set_params(**xgb_cv.best_params_)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Initialize the models. I am doing it this way as predictions are easy to calculate so I will not be storing them until I need them\n",
    "\n",
    "\n",
    "seed = 999\n",
    "models = []\n",
    "models.append(('LinReg', LinearRegression()))\n",
    "models.append(('LassoReg', LassoCV()))\n",
    "models.append(('RidgeReg', RidgeCV()))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def get_cv_scores(models, X, y, k=5, seed=999):\n",
    "    \n",
    "    # inspired by the excellent tutorial by Jason Brownlee:\n",
    "    # https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "    \n",
    "    names = []\n",
    "    results = []\n",
    "    print(\"Cross val scores:\")\n",
    "    \n",
    "    for name, m in models:\n",
    "        cv_results = -cross_val_score(m, X, y, cv=k, scoring='neg_root_mean_squared_error')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        \n",
    "        print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std() ))\n",
    "        print(\"\")\n",
    "        print(\"*\"*88)\n",
    "        print(\"\")\n",
    "        \n",
    "    return names, results\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "model_names, model_results = get_cv_scores(models, X_train_no_na, y_train_no_na)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "xgb_cv_scores = get_cv_scores([(\"XGB\", xgb_best)], X_train, y_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "model_names += xgb_cv_scores[0]\n",
    "model_results += xgb_cv_scores[1]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def compare_model_scores(model_names, model_results):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Model comparison')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(model_results)\n",
    "    ax.set_xticklabels(model_names)\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "compare_model_scores(model_names, model_results)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It looks like XGBoost is the winner here in terms of average RMSE. The other regression models appear to be more or less the same, so I will go with the simple Linear Regression model as the other choice for comparing the transfer selection algorithm."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transfer selection\n",
    "\n",
    "Next, I came up with a heuristic-based algorithm that will decide which transfer, if any, to make for each Gameweek:\n",
    "\n",
    "- For each player position, find the player in the current team with the lowest predicted points. Here, I excluded the Keeper since the variance in points (and thus the potential benefit from a transfer) from Keepers is not very high compared to the other positions.\n",
    "- From the pool of players not in the current team, get all players that (1) have predicted points that are higher than this player, and (2) a cost that is lower than the cost of this player and the current available money\n",
    "- From this pool of players, a potential player will be selected. \n",
    "- Among the 3 potential players selected (1 from each position), the player with the highest predicted point difference, compared against the player that they will replace, will be selected as the final player to be transferred in. \n",
    "- The constraint of not more than 3 players from the same team will also be checked.\n",
    "- There could be cases where all the players from the current team have the highest predicted points for their respective positions. In that case, no transfers will be made."
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def make_predicted_table(y_test, y_pred, gw_df):\n",
    "    results_df = pd.DataFrame(list(zip(y_test.tolist(), y_pred.tolist())),\n",
    "                             columns=[\"actual\", \"predicted\"])\n",
    "    \n",
    "    \n",
    "    results_df.reset_index(drop=True, inplace=True)\n",
    "    gw_df.reset_index(inplace=True)\n",
    "    pred_df = pd.concat([gw_df, results_df], axis=1)\n",
    "    \n",
    "    return pred_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def get_suggested_transfer(predicted_df, team_list, current_money):\n",
    "    \n",
    "    predicted_diff = 0\n",
    "    money_change = 0\n",
    "    suggested_in = ''\n",
    "    suggested_out = ''\n",
    "    team_df = predicted_df[(predicted_df.full_name.isin(team_list))]\n",
    "    \n",
    "  \n",
    "    teams_dict = {}\n",
    "    for i, row in team_df.iterrows():\n",
    "        if row.player_team_name not in teams_dict:\n",
    "            teams_dict[row.player_team_name] = [row.full_name]\n",
    "        else:\n",
    "            teams_dict[row.player_team_name].append(row.full_name)\n",
    "            \n",
    "            \n",
    "    for position in [\"Defender\", \"Midfielder\", \"Forward\"]:\n",
    "        \n",
    "        # don't bother about keepers, variance in scores is not that great\n",
    "        # so, save the free transfer for other positions\n",
    "       \n",
    "        \n",
    "        \n",
    "        player_df = predicted_df[predicted_df.position==position].sort_values('predicted', ascending=False).reset_index()\n",
    "\n",
    "        \n",
    "        lowest_pos = 0\n",
    "        player_names = team_df[team_df.position==position].full_name.values\n",
    "        \n",
    "        # loop through the players for this position, and get the rank (row number) of the player with the lowest predicted score\n",
    "        for p in player_names:\n",
    "            player_pos = player_df[player_df.full_name==p].index[0]\n",
    "            if player_pos > lowest_pos:\n",
    "                lowest_pos = player_pos\n",
    "                potential_out = p\n",
    "                potential_out_cost = team_df[team_df.full_name==p].value.values[0]\n",
    "                potential_out_team = team_df[team_df.full_name==p].player_team_name.values[0]\n",
    "                \n",
    "            elif len(player_names) <= 1:\n",
    "                potential_out_cost = 0\n",
    "                potential_out_team = 'none'\n",
    "                potential_out = 'none'\n",
    "                \n",
    "        # get all players above this player\n",
    "        potential_players = player_df[:lowest_pos]\n",
    "        \n",
    "        \n",
    "        # only keep players that we can afford\n",
    "        potential_players = potential_players[potential_players.value <= potential_out_cost + current_money]\n",
    "        \n",
    "        # only keep players who played (need a better way of doing this)\n",
    "        potential_players = potential_players[potential_players.minutes > 0]\n",
    "\n",
    "        # get the prediction difference for each suggested player\n",
    "        # select the one with the highest difference as the suggested transfer (compare across positons)\n",
    "        \n",
    "        potential_out_predicted = team_df[team_df.full_name==p].predicted.values[0]\n",
    "        \n",
    "        for i, row in potential_players.iterrows():\n",
    "                \n",
    "            # skip if it is a player we already have\n",
    "            if row.full_name in team_list:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "            # if there are no other players of the same team, it's ok to consider this player\n",
    "            # if not, check whether there are 3 players of the same team already\n",
    "            if row.player_team_name not in teams_dict:\n",
    "                pass\n",
    "            else:\n",
    "                if len(teams_dict[row.player_team_name]) == 3:\n",
    "                    # if there are already 3 players of the same team,\n",
    "                    # can't take another player of the same team\n",
    "                    # unless the suggested_out is the same team as suggested_in (direct swap)\n",
    "                   \n",
    "                    if row.player_team_name == potential_out_team:\n",
    "                        pass\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            \n",
    "            # check for difference in predictions\n",
    "            if row.predicted - potential_out_predicted > predicted_diff:\n",
    "                predicted_diff = row.predicted - potential_out_predicted\n",
    "                suggested_in = row.full_name\n",
    "                suggested_out = potential_out\n",
    "                \n",
    "                # calculate change in money\n",
    "                money_change = potential_out_cost - row.value\n",
    "                \n",
    "    return suggested_in, suggested_out, money_change"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def get_score(team_list, gw_df):\n",
    "    \n",
    "    gw_score = gw_df[gw_df.full_name.isin(team_list)].actual.sum() \\\n",
    "        + gw_df[(gw_df.full_name.isin(team_list)) & (gw_df.position!='Keeper')].sort_values(\"predicted\", ascending=False).head(1).actual.values[0]\n",
    "        \n",
    "    \n",
    "    return gw_score"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def get_performance(team_list, starting_money, gw_list,\n",
    "                   prediction_df):\n",
    "    \n",
    "    current_money = starting_money\n",
    "    total_score = 0\n",
    "    \n",
    "    \n",
    "    in_list = []\n",
    "    out_list = []\n",
    "    score_list = []\n",
    "    unplayed_list = []\n",
    "    \n",
    "    \n",
    "    for gw in gw_list:\n",
    "\n",
    "        gw_df = prediction_df[prediction_df.GW==gw]\n",
    "        money_change = 0\n",
    "        suggested_in = ''\n",
    "        suggested_out = ''\n",
    "        if gw > 1:\n",
    "            \n",
    "\n",
    "            suggested_in, suggested_out, money_change = get_suggested_transfer(gw_df, team_list, current_money)\n",
    "        \n",
    "            current_money += money_change\n",
    "\n",
    "            team_list.append(suggested_in)\n",
    "            team_list.remove(suggested_out)\n",
    "            \n",
    "        \n",
    "\n",
    "        ## Calculate scores\n",
    "        \n",
    "        gw_score = get_score(team_list, gw_df)\n",
    "\n",
    "        \n",
    "        out_list.append(suggested_out)\n",
    "        in_list.append(suggested_in)\n",
    "        score_list.append(gw_score)\n",
    "        \n",
    "        total_score += gw_score\n",
    "        \n",
    "    out_df = pd.DataFrame({'GW': gw_list,\n",
    "                          'player_in': in_list,\n",
    "                          'player_out': out_list,\n",
    "                          'total_score': score_list})\n",
    "    \n",
    "    print(total_score)\n",
    "    \n",
    "    return(out_df)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "## Get predictions for the two best models, Linear Regression and XGBoost\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_no_na, y_train_no_na)\n",
    "linreg_predictions = lin_reg.predict(X_test_no_na)\n",
    "\n",
    "\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_best.predict(X_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "predicted_df_lin_reg = make_predicted_table(y_test_no_na, linreg_predictions, test_df_no_na[relevant_features + ['full_name', 'GW', 'player_team_name', 'total_points']] )\n",
    "predicted_df_xgb = make_predicted_table(y_test, xgb_predictions, test_df[relevant_features + ['full_name', 'GW', 'player_team_name', 'total_points']] )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model comparison\n",
    "\n",
    "First, a reminder of the total points that would have been obtained without any transfers:"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "captain = get_initial_team(prob, previous_season_player_df).sort_values(\"total_points\", ascending=False).head(1).full_name.values[0]\n",
    "\n",
    "total_points = current_season_player_df[current_season_player_df.full_name.isin(initial_team_df.full_name)].total_points.sum()\n",
    "total_points += current_season_player_df[current_season_player_df.full_name==captain].total_points\n",
    "\n",
    "print(\"Total points for 19/20 season:\", total_points.values[0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "## Linear regression\n",
    "\n",
    "my_team = list(initial_team_df.full_name)\n",
    "gameweeks = (test_df.GW).unique()\n",
    "starting_money = 1000 - bench_cost - initial_team_df.starting_cost.sum()\n",
    "\n",
    "lin_reg_perf = get_performance(my_team, starting_money, gameweeks,\n",
    "                   predicted_df_lin_reg)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The linear regression model gives a end-of-season score of 2041. Linear regression shows a huge improvement of about 250 points! This corresponds to a ranking of 1457242 (https://fantasy.premierleague.com/entry/222484/history/), or about the top 19% of all managers. Great improvement from 57% just with a simple linear regression model! \n",
    "\n",
    "What about XGBoost?"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "## XGBoost\n",
    "\n",
    "\n",
    "my_team = list(initial_team_df.full_name)\n",
    "gameweeks = (test_df.GW).unique()\n",
    "starting_money = 1000 - bench_cost - initial_team_df.starting_cost.sum()\n",
    "\n",
    "xgb_cv_perf = get_performance(my_team, starting_money, gameweeks,\n",
    "                   predicted_df_xgb)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The XGBoost model gives a end-of-season score of 2219. A more modest, but still substantial, improvement over the linear regression model. This corresponds to a ranking of 79192, or about top 1% of all managers (https://fantasy.premierleague.com/entry/104879/history). XGBoost allowed the team to climb more than 15% ranking points compared to linear regression! Furthermore, I was able to achieve a top 1% ranking! \n"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "xgb_cv_perf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Statistical analysis\n",
    "\n",
    "The total points obtained by the two different models definitely different, but is this difference greater than what would be expected by random chance alone? For example, suppose that the XGBoost regressor resulted in 1 more point that the linear regression model. This difference would likely be due to chance, and we might be better off just using the simpler model.\n",
    "\n",
    "Here, I conducted a paired-samples t-test to determine whether the better performance of the XGBoost model was due to chance:"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "stats.ttest_rel(xgb_cv_perf.total_score, lin_reg_perf.total_score)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Since p = .009, the null hypothesis of \"no difference in the predicted points between the linear regression and XGBoost model\" is rejected (at alpha = .05). Thus, I am confident that there is a meaningful difference between the two models, and that the XGBoost provides better predicted points for the 19/20 FPL season."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Final thoughts\n",
    "\n",
    "As Box once said, \"All models are wrong, but some are useful\". As with all models, we cannot achieve 100% accuracy (ignoring edge cases e.g. a system where the data is deterministic - input of X always gives Y). Models can and do sometimes go wrong, and it would be important to have a human in the loop to determine whether the suggested transfer makes sense or not. For example, the model sometimes makes questionable transfers, such as bringing in Dele Alli for Heung Min Son (Gameweek 28) Nicholas Pepe for Kevin de Bruyne (Gameweek 45). For someone who has been following the 19/20 season, these would raise eyebrows given the excellent form that the \"transferred out\" players were in.  \n",
    "\n",
    "Either way, the final model seems to perform well in the 19/20 season. I am excited to test this out in the 20/21 season, and hopefully make it to the top 1% as predicted!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# To-do:\n",
    "\n",
    "- Add more data sources, e.g. FIFA/Football Manager ratings, bookmaker odds etc.\n",
    "- Add wildcard strategy\n",
    "- Improve initial team selection\n",
    "- Take into account injuries and other reasons for not being able to play (i.e. minutes == 0)\n",
    "- For non-XGBoost regression, impute NA values\n",
    "- Stacked regressors\n",
    "- Re-train the model each Gameweek (and/or use Bayesian methods instead)\n",
    "- Incorporate better strategies/heuristics for making transfers. For example, having a set of MVPs that will not be transferred out (see https://twitter.com/EricDFreeman/status/1154771281490993153)\n",
    "- Move this to github and modularize stuff"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
